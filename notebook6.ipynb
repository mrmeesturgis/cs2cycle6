{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8bba665",
   "metadata": {},
   "source": [
    "<img src=\"https://www.sturgischarterschool.com/wp-content/uploads/2019/06/sturgisheader_logo.png\" alt=\"sturgis\" width=\"250\" align=\"right\"/>\n",
    "\n",
    "## Computer Science 'Vector Paradise' notebook 6\n",
    "### Sturgis Charter Public School \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681696fb",
   "metadata": {},
   "source": [
    "Student: [your name here]\n",
    "\n",
    "Collaborators: [N/A]\n",
    "\n",
    "Notes to the teacher: [N/A]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16bf0839",
   "metadata": {},
   "source": [
    "### Learning Objectives for notebook \n",
    "* Tokens\n",
    "* Vectors\n",
    "* Regular Expressions\n",
    "* Basic probability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf184f53",
   "metadata": {},
   "source": [
    "### Narrative\n",
    "\n",
    "Let's assume that we have two documents. Each are a page long, and while they have some similarities, they are also somewhat different. \n",
    "\n",
    "Now what if want to compute the difference between these two documents? What should we do? There are of course many ways to do this, but we're going to focus on techniques that bridge the gap between words and numbers. We are, in a word asking the following question: how do we calculate (the probability) of words?\n",
    "\n",
    "This is no small task, since language is infinite. The reason it is infinite is actually because of a word we've already encountered: recursion. Consider the following sentences. \n",
    "\n",
    "* The boy saw the cat. \n",
    "* The boy saw the cat who saw the boy.\n",
    "* The boy saw the cat who saw the boy who saw the cat.\n",
    "* The boy saw the cat who saw the boy who saw the dog who made the mess. \n",
    "\n",
    "We could keep doing this infinitely. \n",
    "\n",
    "But back to our documents. Let's borrow from [project gutenburg](https://www.gutenberg.org/). Let's take a look at the first chapter of some classics, Mary Shelley's *Frankenstein* and Bram Stoker's *Dracula*. These two texts are at once quite similar, and also very different. Let's take a moment and consider some of those similarities and differences. Then, let's load those first chapters (see below). \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb3eb272",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "f1 = open('frank.txt', 'r')\n",
    "frank = f1.readlines()\n",
    "f1.close()\n",
    "    \n",
    "d1 = open('dracula.txt', 'r')\n",
    "dracula = d1.readlines()\n",
    "d1.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5eebc19",
   "metadata": {},
   "source": [
    "Now this is pretty raw data. It has a fair amount of messiness built into it. Let's see if we can't clean that up a bit. Right now we have a list of essentially lines. That's not very useful to us. It would be much better if were to **tokenize** these documents, which is to say have lists of individual words. It might be worth keeping the words in their sentences (more on that later), but we also have to get rid of some annoying data like the `'\\n'` and `'`. To do this we are going to use an import called:\n",
    "> regex\n",
    "\n",
    "We've actually used a few other imports such as: \n",
    "> random, csv\n",
    "\n",
    "These imports extend what Python can do in it's base form, and these are incredibly powerful. Let's get to work!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f3a61b",
   "metadata": {},
   "source": [
    "### Question 1: Preprocessing\n",
    "\n",
    "Let's clean this up a bit. Use `re.sub` to get rid of some of the junk that's not useful for processing. This should include things such as `\\n, ', \", “, ”, -, (, )`. Don't forget that for some of these characters you're going to have to use `\\` as an escape character. **Also cast everything into lowercase**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5237394",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = []\n",
    "#Write your code here\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7f94212",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "assert answer[4] == 'we left in pretty good time and came after nightfall to klausenburgh. here i stopped for the night at the hotel royale. i had for dinner or rather supper a chicken done up some way with red pepper which was very good but thirsty. mem. get recipe for mina. i asked the waiter and he said it was called paprika hendl and that as it was a national dish i should be able to get it anywhere along the carpathians. i found my smattering of german very useful here; indeed i don’t know how i should be able to get on without it.'\n",
    "assert answer[-5] == 'it was on the dark side of twilight when we got to bistritz which is a very interesting old place. being practically on the frontierfor the borgo pass leads from it into bukovinait has had a very stormy existence and it certainly shows marks of it. fifty years ago a series of great fires took place which made terrible havoc on five separate occasions. at the very beginning of the seventeenth century it underwent a siege of three weeks and lost 13000 people the casualties of war proper being assisted by famine and disease.'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34d9b7a",
   "metadata": {},
   "source": [
    "### Question 2: Tokenizing\n",
    "Now use the re.split method to tokenize each sentence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e0d3da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = []\n",
    "#Write your code here\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82053dca",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "assert tokens[4] == ['we', 'left', 'in', 'pretty', 'good', 'time', 'and', 'came', 'after', 'nightfall', 'to', 'klausenburgh.', 'here', 'i', 'stopped', 'for', 'the', 'night', 'at', 'the', 'hotel', 'royale.', 'i', 'had', 'for', 'dinner', 'or', 'rather', 'supper', 'a', 'chicken', 'done', 'up', 'some', 'way', 'with', 'red', 'pepper', 'which', 'was', 'very', 'good', 'but', 'thirsty.', 'mem.', 'get', 'recipe', 'for', 'mina.', 'i', 'asked', 'the', 'waiter', 'and', 'he', 'said', 'it', 'was', 'called', 'paprika', 'hendl', 'and', 'that', 'as', 'it', 'was', 'a', 'national', 'dish', 'i', 'should', 'be', 'able', 'to', 'get', 'it', 'anywhere', 'along', 'the', 'carpathians.', 'i', 'found', 'my', 'smattering', 'of', 'german', 'very', 'useful', 'here;', 'indeed', 'i', 'don’t', 'know', 'how', 'i', 'should', 'be', 'able', 'to', 'get', 'on', 'without', 'it.']\n",
    "assert tokens[-5] == ['it', 'was', 'on', 'the', 'dark', 'side', 'of', 'twilight', 'when', 'we', 'got', 'to', 'bistritz', 'which', 'is', 'a', 'very', 'interesting', 'old', 'place.', 'being', 'practically', 'on', 'the', 'frontierfor', 'the', 'borgo', 'pass', 'leads', 'from', 'it', 'into', 'bukovinait', 'has', 'had', 'a', 'very', 'stormy', 'existence', 'and', 'it', 'certainly', 'shows', 'marks', 'of', 'it.', 'fifty', 'years', 'ago', 'a', 'series', 'of', 'great', 'fires', 'took', 'place', 'which', 'made', 'terrible', 'havoc', 'on', 'five', 'separate', 'occasions.', 'at', 'the', 'very', 'beginning', 'of', 'the', 'seventeenth', 'century', 'it', 'underwent', 'a', 'siege', 'of', 'three', 'weeks', 'and', 'lost', '13000', 'people', 'the', 'casualties', 'of', 'war', 'proper', 'being', 'assisted', 'by', 'famine', 'and', 'disease.'] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f80e3c2",
   "metadata": {},
   "source": [
    "### Question 3: Getting word counts\n",
    "Now, let's get some word counts. How many times does each word appear in the entire text?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5e98eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcount = {}\n",
    "#Write your code here\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8b5977e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "assert wordcount['time'] == 3\n",
    "assert wordcount['paprika'] == 3\n",
    "assert wordcount['had'] == 18"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f11658",
   "metadata": {},
   "source": [
    "### Question 4: Stopwords\n",
    "Some words just aren't useful. `the` occurs over 80 times in the text, and as a result it acts as static. Let's get rid of words like these. They are generally called stopwords. I'll give you a list of stopwords that should be present in your wordcount dictionary. Remove those elements from both your wordcount dictionary **and** your tokens list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09918226",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = ['the', 'of', 'i', 'and', 'to', 'in', 'a', 'had', \n",
    "             'for', 'it', 'was', 'with', 'my', 'at', 'very',\n",
    "             'on', 'which', 'they', 'as', 'we', 'that', 'some',\n",
    "             'were', 'be', 'all', 'but', 'from', 'or', 'when', 'them']\n",
    "newtokens = []\n",
    "#Write your code here\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dab35cd4",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Checking the wordcount dictionary\n",
    "for word in stopwords:\n",
    "    assert word not in wordcount, word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8c4ff7e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Checking the newtokens list\n",
    "assert newtokens[4] == ['left', 'pretty', 'good', 'time', 'came', 'after', 'nightfall', 'klausenburgh.', 'here', 'stopped', 'night', 'hotel', 'royale.', 'dinner', 'rather', 'supper', 'chicken', 'done', 'up', 'way', 'red', 'pepper', 'good', 'thirsty.', 'mem.', 'get', 'recipe', 'mina.', 'asked', 'waiter', 'he', 'said', 'called', 'paprika', 'hendl', 'national', 'dish', 'should', 'able', 'get', 'anywhere', 'along', 'carpathians.', 'found', 'smattering', 'german', 'useful', 'here;', 'indeed', 'don’t', 'know', 'how', 'should', 'able', 'get', 'without', 'it.']\n",
    "assert newtokens[-5] == ['dark', 'side', 'twilight', 'got', 'bistritz', 'is', 'interesting', 'old', 'place.', 'being', 'practically', 'frontierfor', 'borgo', 'pass', 'leads', 'into', 'bukovinait', 'has', 'stormy', 'existence', 'certainly', 'shows', 'marks', 'it.', 'fifty', 'years', 'ago', 'series', 'great', 'fires', 'took', 'place', 'made', 'terrible', 'havoc', 'five', 'separate', 'occasions.', 'beginning', 'seventeenth', 'century', 'underwent', 'siege', 'three', 'weeks', 'lost', '13000', 'people', 'casualties', 'war', 'proper', 'being', 'assisted', 'by', 'famine', 'disease.']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d3fccf",
   "metadata": {},
   "source": [
    "### Question 5: Vectors\n",
    "Now let's build a vector.\n",
    "> Vector: a quantity having direction as well as magnitude, especially as determining the position of one point in space relative to another. (Thanks Google)\n",
    "\n",
    "A vector is best rendered in a dictionary. The key is the word, and the value is a list of all the words that happened in the same sentence as that word. Be careful! Sometimes those words are in multiple sentences, your vector should be built across all of these. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15d01a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's build some vectors. Create a dictionary \n",
    "vectors = {}\n",
    "#Write your code here\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc51f3b6",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "assert vectors['train'] == ['3', 'may.', 'bistritz.left', 'munich', '8:35', 'p.', 'm.', '1st', 'may', 'arriving', 'vienna', 'early', 'next', 'morning;', 'should', 'have', 'arrived', '6:46', 'an', 'hour', 'late.', 'buda-pesth', 'seems', 'wonderful', 'place', 'glimpse', 'got', 'little', 'could', 'walk', 'through', 'streets.', 'feared', 'go', 'far', 'station', 'late', 'would', 'start', 'near', 'correct', 'time', 'possible.', 'impression', 'leaving', 'west', 'entering', 'east;', 'most', 'western', 'splendid', 'bridges', 'over', 'danube', 'is', 'here', 'noble', 'width', 'depth', 'took', 'us', 'among', 'traditions', 'turkish', 'rule.', 'did', 'not', 'sleep', 'well', 'though', 'bed', 'comfortable', 'enough', 'sorts', 'queer', 'dreams.', 'there', 'dog', 'howling', 'night', 'under', 'window', 'something', 'do', 'it;', 'been', 'paprika', 'drink', 'up', 'water', 'carafe', 'still', 'thirsty.', 'towards', 'morning', 'slept', 'wakened', 'by', 'continuous', 'knocking', 'door', 'so', 'guess', 'must', 'sleeping', 'soundly', 'then.', 'breakfast', 'more', 'sort', 'porridge', 'maize', 'flour', 'said', 'mamaliga', 'egg-plant', 'stuffed', 'forcemeat', 'excellent', 'dish', 'call', 'impletata.', 'mem.', 'get', 'recipe', 'this', 'also.', 'hurry', 'started', 'before', 'eight', 'rather', 'ought', 'done', 'after', 'rushing', '7:30', 'sit', 'carriage', 'than', 'began', 'move.', 'me', 'further', 'east', 'you', 'unpunctual', 'are', 'trains.', 'what', 'china?']\n",
    "assert vectors['transylvania'] == ['having', 'time', 'disposal', 'london', 'visited', 'british', 'museum', 'made', 'search', 'among', 'books', 'maps', 'library', 'regarding', 'transylvania;', 'struck', 'me', 'foreknowledge', 'country', 'could', 'hardly', 'fail', 'have', 'importance', 'dealing', 'nobleman', 'country.', 'find', 'district', 'he', 'named', 'is', 'extreme', 'east', 'just', 'borders', 'three', 'states', 'moldavia', 'bukovina', 'midst', 'carpathian', 'mountains;', 'one', 'wildest', 'least', 'known', 'portions', 'europe.', 'not', 'able', 'light', 'any', 'map', 'work', 'giving', 'exact', 'locality', 'castle', 'dracula', 'there', 'are', 'no', 'this', 'yet', 'compare', 'our', 'own', 'ordnance', 'survey', 'maps;', 'found', 'bistritz', 'post', 'town', 'by', 'count', 'fairly', 'well-known', 'place.', 'shall', 'enter', 'here', 'notes', 'may', 'refresh', 'memory', 'talk', 'over', 'travels', 'mina.', 'population', 'four', 'distinct', 'nationalities:', 'saxons', 'south', 'mixed', 'wallachs', 'who', 'descendants', 'dacians;', 'magyars', 'west', 'szekelys', 'north.', 'am', 'going', 'latter', 'claim', 'descended', 'attila', 'huns.', 'so', 'conquered', 'eleventh', 'century', 'huns', 'settled', 'it.', 'read', 'every', 'superstition', 'world', 'gathered', 'into', 'horseshoe', 'carpathians', 'if', 'centre', 'sort', 'imaginative', 'whirlpool;', 'stay', 'interesting.', 'mem.', 'must', 'ask', 'about', 'them.']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45b967a",
   "metadata": {},
   "source": [
    "### Question 6: Putting it all together in a function\n",
    "\n",
    "Alright, now that we've got all the pieces, let's see if we can't get everything into a function. This should be as simple as stitching it all together in a function, and making sure that we pass back the correct returns. We are going to return three things. We're going to return the tokens without stopwords, we're going to return the wordcount dictionary, and we're going to return the vectors dictionary.\n",
    "\n",
    "It might be useful to know that `Ctrl + ]` will shift a block of highlighted text to the right. `Ctrl + [` does the opposite (here + means 'and', don't actually press the `+` key).\n",
    "\n",
    "One other thing: the stopword `very` is not in Frankenstein. You'll have to get rid of that from your list of stopwords within the function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a794580",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing(text):\n",
    "    #Write your code here\n",
    "    raise NotImplementedError()\n",
    "    return newtokens, wordcount, vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b010e0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ftokens, fwcount, fvectors = processing(frank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62369533",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "assert ftokens[5] == ['these', 'reflections', 'have', 'dispelled', 'agitation', 'began', 'letter', 'feel', 'heart', 'glow', 'an', 'enthusiasm', 'elevates', 'me', 'heaven', 'nothing', 'contributes', 'so', 'much', 'tranquillise', 'mind', 'steady', 'purposea', 'point', 'soul', 'may', 'fix', 'its', 'intellectual', 'eye.', 'this', 'expedition', 'has', 'been', 'favourite', 'dream', 'early', 'years.', 'have', 'read', 'ardour', 'accounts', 'various', 'voyages', 'have', 'been', 'made', 'prospect', 'arriving', 'north', 'pacific', 'ocean', 'through', 'seas', 'surround', 'pole.', 'you', 'may', 'remember', 'history', 'voyages', 'made', 'purposes', 'discovery', 'composed', 'whole', 'our', 'good', 'uncle', 'thomas’', 'library.', 'education', 'neglected', 'yet', 'passionately', 'fond', 'reading.', 'these', 'volumes', 'study', 'day', 'night', 'familiarity', 'increased', 'regret', 'felt', 'child', 'learning', 'father’s', 'dying', 'injunction', 'forbidden', 'uncle', 'allow', 'me', 'embark', 'seafaring', 'life.']\n",
    "assert ftokens[-5] == ['this', 'is', 'most', 'favourable', 'period', 'travelling', 'russia.', 'fly', 'quickly', 'over', 'snow', 'their', 'sledges;', 'motion', 'is', 'pleasant', 'opinion', 'far', 'more', 'agreeable', 'than', 'an', 'english', 'stagecoach.', 'cold', 'is', 'not', 'excessive', 'if', 'you', 'are', 'wrapped', 'fursa', 'dress', 'have', 'already', 'adopted', 'there', 'is', 'great', 'difference', 'between', 'walking', 'deck', 'remaining', 'seated', 'motionless', 'hours', 'no', 'exercise', 'prevents', 'blood', 'actually', 'freezing', 'your', 'veins.', 'have', 'no', 'ambition', 'lose', 'life', 'post-road', 'between', 'st.', 'petersburgh', 'archangel.']\n",
    "\n",
    "assert fwcount['heaven'] == 2\n",
    "assert fwcount['snow'] == 2\n",
    "\n",
    "assert fvectors['ambition'] == ['this', 'is', 'most', 'favourable', 'period', 'travelling', 'russia.', 'fly', 'quickly', 'over', 'snow', 'their', 'sledges;', 'motion', 'pleasant', 'opinion', 'far', 'more', 'agreeable', 'than', 'an', 'english', 'stagecoach.', 'cold', 'not', 'excessive', 'if', 'you', 'are', 'wrapped', 'fursa', 'dress', 'have', 'already', 'adopted', 'there', 'great', 'difference', 'between', 'walking', 'deck', 'remaining', 'seated', 'motionless', 'hours', 'no', 'exercise', 'prevents', 'blood', 'actually', 'freezing', 'your', 'veins.', 'lose', 'life', 'post-road', 'st.', 'petersburgh', 'archangel.']\n",
    "assert fvectors['heart'] == ['these', 'reflections', 'have', 'dispelled', 'agitation', 'began', 'letter', 'feel', 'glow', 'an', 'enthusiasm', 'elevates', 'me', 'heaven', 'nothing', 'contributes', 'so', 'much', 'tranquillise', 'mind', 'steady', 'purposea', 'point', 'soul', 'may', 'fix', 'its', 'intellectual', 'eye.', 'this', 'expedition', 'has', 'been', 'favourite', 'dream', 'early', 'years.', 'read', 'ardour', 'accounts', 'various', 'voyages', 'made', 'prospect', 'arriving', 'north', 'pacific', 'ocean', 'through', 'seas', 'surround', 'pole.', 'you', 'remember', 'history', 'purposes', 'discovery', 'composed', 'whole', 'our', 'good', 'uncle', 'thomas’', 'library.', 'education', 'neglected', 'yet', 'passionately', 'fond', 'reading.', 'volumes', 'study', 'day', 'night', 'familiarity', 'increased', 'regret', 'felt', 'child', 'learning', 'father’s', 'dying', 'injunction', 'forbidden', 'allow', 'embark', 'seafaring', 'life.']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee84bc7",
   "metadata": {},
   "source": [
    "### Question 7: Now let's compare [HL Question]\n",
    "This question you do not need to write code for, though you are welcomed and encourage to use your code to guide your response. \n",
    "\n",
    "I'm going to give you an excerpt from an unknown text. I want you to tell me. Do you think that it is an excerpt from either:\n",
    "* Dracula\n",
    "* Frankenstein\n",
    "* Some other text\n",
    "\n",
    "Then be sure to explain with at least a paragraph how you decided which was the correct answer. The text is rendered below. \n",
    "\n",
    "#### Your answer here:\n",
    "\n",
    "[your answer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "843e1201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['It was six months after this miserable conclusion to his long nursed hopes that I first saw him. He had retired to a part of the country where he was not known that he might peacefully indulge his grief. All the world, by the death of his beloved Elinor, was changed to him, and he could no longer remain in any spot where he had seen her or where her image mingled with the most rapturous hopes had brightened all around with a light of joy which would now be transformed to a darkness blacker than midnight since she, the sun of his life, was set for ever.\\n', '\\n', 'He lived for some time never looking on the light of heaven but shrouding his eyes in a perpetual darkness far from all that could remind him of what he had been; but as time softened his grief like a true child of Nature he sought in the enjoyment of her beauties for a consolation in his unhappiness. He came to a part of the country where he was entirely unknown and where in the deepest solitude he could converse only with his own heart. He found a relief to his impatient grief in the breezes of heaven and in the sound of waters and woods. He became fond of riding; this exercise distracted his mind and elevated his spirits; on a swift horse he could for a moment gain respite from the image that else for ever followed him; Elinor on her death bed, her sweet features changed, and the soft spirit that animated her gradually waning into extinction. For many months Woodville had in vain endeavoured to cast off this terrible remembrance; it still hung on him untill memory was too great a burthen for his loaded soul, but when on horseback the spell that seemingly held him to this idea was snapt; then if he thought of his lost bride he pictured her radiant in beauty; he could hear her voice, and fancy her “a sylvan Huntress by his side,” while his eyes brightened as he thought he gazed on her cherished form. I had several times seen him ride across the heath and felt angry that my solitude should be disturbed. It was so long [since] I had spoken to any but peasants that I felt a disagreable sensation at being gazed on by one of superior rank. I feared also that it might be some one who had seen me before: I might be recognized, my impostures discovered and I dragged back to a life of worse torture than that I had before endured. These were dreadful fears and they even haunted my dreams\\n']\n"
     ]
    }
   ],
   "source": [
    "uk = open('unknown.txt', 'r')\n",
    "unknown = uk.readlines()\n",
    "print(unknown)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b7377e",
   "metadata": {},
   "source": [
    "### Question 8: Probability [HL Question]\n",
    "\n",
    "1. Given two fair six sided dice, what is the most probable number. Explain why that number is the most probable number.\n",
    "\n",
    "[Your answer here]\n",
    "\n",
    "2. I rolled a 5, what is the probability that the next number I roll will be another 5?\n",
    "\n",
    "[Your answer here]\n",
    "\n",
    "![dice](dice.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
